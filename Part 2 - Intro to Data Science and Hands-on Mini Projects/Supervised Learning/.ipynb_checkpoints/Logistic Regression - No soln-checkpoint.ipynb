{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:06:27.382555Z",
     "start_time": "2019-07-12T13:06:26.192362Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Iris Dataset that contains 4 features/ measurements (*petal length, petal width, sepal length, sepal width*) of **50 samples of 3 species of Iris flower (*Iris setosa, Iris Versicolor, Iris Virginica*) = 50×3 = 150 samples in total**. This is one of the best known datasets till date. For more details on the dataset, visit <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris\">UCI Machine Learning Repository - IRIS dataset</a>.\n",
    "\n",
    "For reference, here are pictures of the three flowers species:\n",
    "<img src=\"images/iris-machinelearning.png\" width =50%>\n",
    "\n",
    "Here is picture showing the 4 measurements made from each flower:\n",
    "<img src=\"images/iris_flower_petal_sepal.jpeg\" width =20%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can download it into our program from `scikit-learn` datasets module. To load the data, we need to use `load_iris()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:53:02.269464Z",
     "start_time": "2019-07-16T05:52:59.129123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load iris dataset #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T11:42:21.583027Z",
     "start_time": "2019-07-12T11:42:21.574030Z"
    }
   },
   "source": [
    "The `load_iris()` function returns the data in `dict` format, that contains key, value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:53:02.298439Z",
     "start_time": "2019-07-16T05:53:02.272452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inside iris dataset #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Details of the `iris_dataset` keys & values*\n",
    "\n",
    "- `DESCR` - Short description of the dataset\n",
    "- `feature_names` - the name of 4 measurements made from each flower\n",
    "- `target_names` - the name of 3 species of the flowers that we are going to work with\n",
    "- `data` - contains numeric measurements of sepal length, sepal width, petal length and petal width in numpy array(all in cm)\n",
    "- `target` - Species that each flower belongs to\n",
    "    - `0` means Setosa\n",
    "    - `1` means Versicolour\n",
    "    - `2` means Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:54.978874Z",
     "start_time": "2019-07-12T13:22:54.947890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Target flower species names #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:55.002869Z",
     "start_time": "2019-07-12T13:22:54.983870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature measurements made from each flower #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:55.042835Z",
     "start_time": "2019-07-12T13:22:55.007856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shape of data containing numeric measurements (aka features) of 150 flowers #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:55.089809Z",
     "start_time": "2019-07-12T13:22:55.049833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature data from first 5 row/ flower entries #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:55.131785Z",
     "start_time": "2019-07-12T13:22:55.096806Z"
    }
   },
   "outputs": [],
   "source": [
    "# target is a 1D array which contains detail of which species the flowers belong to#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:55.171764Z",
     "start_time": "2019-07-12T13:22:55.139780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see the species/ target class of all the flowers #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:22:55.199746Z",
     "start_time": "2019-07-12T13:22:55.177759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prints the flowers measurements data (features) and corresponding target (class label)\n",
    "i = 0\n",
    "print (\"Feature:\", iris_dataset['data'][i])\n",
    "print (\"Label  :\",iris_dataset['target'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T11:51:35.305752Z",
     "start_time": "2019-07-12T11:51:35.300757Z"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 input feature and 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:28.852519Z",
     "start_time": "2019-07-12T13:23:28.846536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's load only the first feature (sepal length) out of 4 features => Univariate #\n",
    "# Let's use only the first two classes => Binary Classification #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous post, we learn that for <b>regression</b>, the prediction formula for <b>a linear model with one input feature (variable)</b> is\n",
    "\n",
    "- `ŷ = w[1]*x[1] + b = w*x + b`\n",
    "\n",
    "<p>Linear models can also be used for <b>classificaiton</b>. For <span title=\"Classification with 2 types of categories (0 or 1) | (+ve or -ve)\" style=\"text-decoration:none;color:black;border: 1px; border-style:dotted; border-color:gray;\">binary classification</span>, the prediction formula for **a linear model with one input feature (variable)** is</p>\n",
    "\n",
    "- `ŷ = w[1]*x[1] + b > 0` or `w*x + b > 0`\n",
    "\n",
    "The formula looks very similar to linear regression, except we threshold the `predicted value` aka `weighted sum of features` (`w*x + b`) at zero \n",
    "\n",
    "<p style=\"color:blue; font-size:110%;  border-left: 5px solid blue; padding-left: 10px;\">If the predicted output is <b>smaller than 0</b>, we predict the input as <b>-ve class</b></p>\n",
    "<p style=\"color:purple; font-size:110%;  border-left: 5px solid blue; padding-left: 10px;\">If the predicted output is <b>greater than 0</b>, we predict the input as <b>+ve class</b></p>\n",
    "\n",
    "Here, \n",
    "- `x` denotes the input features (`x[1]` is input feature of a single data point) and, \n",
    "- `ŷ` denotes the classification made by the model (could be `<0 = +ve class` or `>0 = -ve class`).\n",
    "- `w` is the slope (*weights or coefficients*) along each feature axis (`w[1]` is slope along axis `x[1]`)\n",
    "- `b` is the intercept (offset) along `y-axis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`w*x + b` is called as **Decision boundary** in logistic regression. It decides which class or category the input belongs to.\n",
    "\n",
    "<ul style=\"color:purple; font-size:110%;  border-left: 5px solid blue; padding-left: 20px; list-style: none; line-height: 190%;\"> For a binary linear classifier, the two classes are separated by a <font size=\"+2\">Decision Boundary</font> which could be a line, a plane, or hyperplane.</ul></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:29.293746Z",
     "start_time": "2019-07-12T13:23:29.046350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's plot the feature and their corresponding class #\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "inline_rc = dict(mpl.rcParams)\n",
    "\n",
    "plt.plot(data[target==0], np.zeros(np.sum(target==0)), 'x')\n",
    "plt.plot(data[target==1], np.ones(np.sum(target==0)), 'x')\n",
    "\n",
    "plt.legend(['class 0: setosa', 'class 1: versicolor'])\n",
    "plt.grid()\n",
    "plt.xlabel('Feature: sepal length (cm)')\n",
    "plt.ylabel('Target class or label')\n",
    "\n",
    "plt.title(\"One input feature\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:30.254493Z",
     "start_time": "2019-07-12T13:23:30.246496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's split the data into train (75%) and test (25%)#\n",
    "\n",
    "\n",
    "\n",
    "print ('Train set:', X_train.shape, Y_train.shape)\n",
    "print ('Test set :', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">sklearn.linear_model.LogisticRegression</a>\n",
    "\n",
    "The most commonly used linear classification algorithm is logistic regression. Keep in mind that, logisitic regression is a classification algorithm and not a regression algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:30.439288Z",
     "start_time": "2019-07-12T13:23:30.430309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's train the LR model #\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:53:40.040121Z",
     "start_time": "2019-07-16T05:53:39.941180Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict from the learned model #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:30.855271Z",
     "start_time": "2019-07-12T13:23:30.846258Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the specified input data in variable 'i', lets see the actual class label vs predicted class label\n",
    "i = 0\n",
    "print (\"For input X =\", X_train[i],\n",
    "       \"\\nPredicted probability =\", lr.predict_proba(X_train[i:i+1])[0,1],\n",
    "       \"\\nPredicted class label =\", lr.predict(X_train[i:i+1])[0],\n",
    "       \"\\nActual class label =\", Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:31.381757Z",
     "start_time": "2019-07-12T13:23:31.090415Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Compute decision boundary and plot with the input data ###\n",
    "x = np.arange(4,8,.005).reshape(-1,1)\n",
    "probs = lr.predict(x)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.plot(data[target==0], np.zeros(np.sum(target==0)), 'x')\n",
    "plt.plot(data[target==1], np.ones(np.sum(target==0)), 'x')\n",
    "\n",
    "plt.axvspan(np.min(x[probs==0]), np.max(x[probs==0]), alpha=0.2)\n",
    "plt.axvspan(np.min(x[probs==1]), np.max(x[probs==1]), alpha=0.2, color='orange')\n",
    "\n",
    "plt.legend(['class 0: actual data', 'class 1: actual data', 'class 0', 'class 1'])\n",
    "plt.grid()\n",
    "plt.xlabel('Feature: sepal length (cm)')\n",
    "plt.ylabel('Target class or label')\n",
    "plt.xlim(4,8)\n",
    "plt.title('Decision boundary for class 0 and class 1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:23:32.847195Z",
     "start_time": "2019-07-12T13:23:32.837222Z"
    }
   },
   "outputs": [],
   "source": [
    "# train and test accuracy of the model #\n",
    "print(\"Train set accuracy: {:.2f}\".format(lr.score(X_train, Y_train)))\n",
    "print(\"Test set accuracy : {:.2f}\".format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:24:10.844241Z",
     "start_time": "2019-07-12T13:24:10.823253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's load all the four features => Multivariate #\n",
    "# Let's use only the first two classes => Binary Classification #\n",
    "data = iris_dataset['data'][:100][:,:]\n",
    "target = iris_dataset['target'][:100]\n",
    "\n",
    "# Split the data intro train and test #\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    random_state=0)\n",
    "print ('Train set:', X_train.shape, Y_train.shape)\n",
    "print ('Test set :', X_test.shape, Y_test.shape)\n",
    "\n",
    "# Train the LR model #\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "# Train and Test Accuracy #\n",
    "print(\"Train set accuracy: {:.2f}\".format(lr.score(X_train, Y_train)))\n",
    "print(\"Test set accuracy : {:.2f}\".format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All 3 input features and all 3 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:24:46.320159Z",
     "start_time": "2019-07-12T13:24:46.310148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's load all the four features => Multivariate #\n",
    "# Let's use all the 3 classes=> Multiclass Classification #\n",
    "data = iris_dataset['data']\n",
    "target = iris_dataset['target']\n",
    "\n",
    "# Split the data intro train and test #\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    random_state=0)\n",
    "print ('Train set:', X_train.shape, Y_train.shape)\n",
    "print ('Test set :', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:24:50.309551Z",
     "start_time": "2019-07-12T13:24:47.734224Z"
    }
   },
   "outputs": [],
   "source": [
    "### Scatter matrix plot for all the 4 features ###\n",
    "\n",
    "\n",
    "# create pandas datafrome from data in X_train\n",
    "# label the 4 columns using the iris_dataset.feature names \n",
    "\n",
    "\n",
    "# create a scatter matrix from dataframe\n",
    "# color the scatter using Y_train target label/class data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:24:55.161148Z",
     "start_time": "2019-07-12T13:24:50.312549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Alternatively, we can use seaborn library to make the scatter plot #\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "df = sns.load_dataset(\"iris\")\n",
    "sns.pairplot(df, hue=\"species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:10:13.645219Z",
     "start_time": "2019-07-12T13:10:13.633246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the LR model for multiclass (all 3 classes) #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:10:51.170428Z",
     "start_time": "2019-07-12T13:10:51.159435Z"
    }
   },
   "outputs": [],
   "source": [
    "# For the specified input data in variable 'i', lets see the actual class label vs predicted class label #\n",
    "i = 1\n",
    "print (\"For input X =\", X_train[i],\n",
    "       \"\\nPredicted probability =\", lr.predict_proba(X_train[i:i+1]),\n",
    "       \"\\nPredicted class label =\", lr.predict(X_train[i:i+1]),\n",
    "       \"\\nActual class label =\", Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:10:51.417087Z",
     "start_time": "2019-07-12T13:10:51.407092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and Test Accuracy #\n",
    "print(\"Train set accuracy: {:.2f}\".format(lr.score(X_train, Y_train)))\n",
    "print(\"Test set accuracy : {:.2f}\".format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\">sklearn.linear_model.LogisticRegressionCV</a>\n",
    "\n",
    "Allows to internally tune the models parameters and choose the settings that gives optimal result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:30:56.327006Z",
     "start_time": "2019-07-12T13:30:55.734091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train a LR model with auto tuning based on CV #\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(verbose=0,multi_class='auto',cv=3).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:30:57.285386Z",
     "start_time": "2019-07-12T13:30:57.272397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients learned by the model, train and test accuracy #\n",
    "print (\"Coefficients:\", lr.coef_, \"\\nIntercept   :\",lr.intercept_)\n",
    "\n",
    "print(\"Train set accuracy: {:.2f}\".format(lr.score(X_train, Y_train)))\n",
    "print(\"Test set accuracy : {:.2f}\".format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : <a href=\"https://scikit-learn.org/stable/modules/preprocessing.html\"> sklearn.preprocessing.StandardScaler </a>.\n",
    "    \n",
    "- Standardization of datasets is a common requirement for many machine learning estimators (models) implemented in scikit-learn; \n",
    "- they might behave badly if the individual features do not more or less look like standard normally distributed data:\n",
    "    - Gaussian with zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:30:58.391283Z",
     "start_time": "2019-07-12T13:30:58.382290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardise the Train and Test data #\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) # Scaled data has zero mean and unit variance #\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:30:59.007855Z",
     "start_time": "2019-07-12T13:30:58.997858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and Test scaled info #\n",
    "print (\"Train :\", X_train_scaled.mean(axis=0), X_train_scaled.std(axis=0))\n",
    "print (\"Test  :\", X_test_scaled.mean(axis=0), X_test_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:31:49.033879Z",
     "start_time": "2019-07-12T13:31:48.789814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the LR model on scaled data #\n",
    "lr = LogisticRegressionCV(verbose=0,multi_class='auto',cv=3).fit(X_train_scaled,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:31:49.856572Z",
     "start_time": "2019-07-12T13:31:49.845580Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients learned by the model, Train and Test Accuracy #\n",
    "print (\"Coefficients:\", lr.coef_, \"\\nIntercept   :\",lr.intercept_)\n",
    "\n",
    "print(\"Train set accuracy: {:.2f}\".format(lr.score(X_train_scaled, Y_train)))\n",
    "print(\"Test set accuracy : {:.2f}\".format(lr.score(X_test_scaled, Y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
